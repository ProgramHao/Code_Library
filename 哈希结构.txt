//用开散列的方法是哈希思想中用的最多的。
//这里用开散列的方法解决哈希冲突，与上面区分，重新定义一个命名空间
namespace HashBucket
{
	//该类作为哈希桶里的元素 的类类型，因为每个哈希桶就是一个单链表，
	//因为是将数据存放在哈希桶里的，哈希桶就是一个单链表，单链表就是由节点组成，
	//哈希表里存放的是指向单链表里头节点(即第一个节点)的指针
	template<class K, class V>
	struct HashNode
	{
		pair<K, V> _kv;
		//指向下一个节点的指针
		HashNode<K, V>* _next;

		//构造函数
		HashNode(const pair<K, V>& kv)
			:_kv(kv) //初始化列表
			, _next(nullptr)
		{}
	};



	//用于哈希表第三个类模板接收仿函数。
	//这里就是仿函数
	template<class K>
	struct HashFunc
	{
		//将复杂类型的键值(关键码)key转换成无符号整型
		size_t operator()(const K& key)
		{
			//强制类型转换成无符号整型
			return (size_t)key;
		}
	};


	//这里是哈希表第三个模板参数接收仿函数，接收的若不是下面的类的特化，
	// 自己也不想用默认的，那么就需要在测试用例TestHT2()中，
	// 就要用HashTable<string, int, HashFunc<String>>进行哈希表的实例化
	//struct HashFuncString
		//{
		//	size_t operator()(const string& key)
		//	{
		//		size_t val = 0;
		//		for (auto ch : key)
		//		{
		//			val += ch;
		//		}
		//
		//		return val;
		//	}
		//};


	//第三个类模板参数hash不用默认的，就可以自己传想用的。
	//这里用类的特化，可以用HashTable<string, int>进行实例化，
	//这里用类的特化，那么在测试用例TestHT2()中，
	//依旧可以用HashTable<string, int>进行实例化，
	//那么哈希表的第三个模板参数用的也不是默认的，也是下面类的特化，
	//因为编译器回去找最匹配的类模板参数！
	template<>
	struct HashFunc<string> //类的特化，因为键值key可能是字符串string
	{
		// BKDR
		size_t operator()(const string& key) //将字符串转化成可以 模% 的整型
		{
			size_t val = 0;
			for (auto ch : key)
			{
				//为了防止下面的测试用例TestHT3()中，该仿函数返回值相同，
				//这里用BKDR这个大佬写了一个算法，就是每一次的值都乘以131，
				//这样就能保证测试用例TestHT3()中，不会出现该仿函数返回值相同的问题，
				//但是这里为什么要乘以131了？？这里应该是数学上的知识，记住就行！
				val *= 131;
				val += ch;
			}

			return val;
		}
	};




	//内联函数
	//这也是源码里面写的一个成员函数，这个成员函数的意义就是自己控制哈希表的空间大小，
	//n就是当前的哈希表的空间大小，也就是有效数据的个数，在函数内部判断，返回需要扩容的新表的空间大小
	inline size_t __stl_next_prime(size_t n)
	{
		//如果const的静态整型变量做成员变量，是可以给缺省值的，
		//其他的静态修饰的变量做成员变量，就不能给缺省值，
		//当然这里是定义在函数内的局部变量，就避免的上面的情况
		static const size_t __stl_num_primes = 28;
		//这里就给了一个数组
		static const size_t __stl_prime_list[__stl_num_primes] =
		{
			53, 97, 193, 389, 769,
			1543, 3079, 6151, 12289, 24593,
			49157, 98317, 196613, 393241, 786433,
			1572869, 3145739, 6291469, 12582917, 25165843,
			50331653, 100663319, 201326611, 402653189, 805306457,
			1610612741, 3221225473, 4294967291
			//为什么最大是4294967291，因为我们加入有效数据个数为4294967291，
			//那么只算哈希表占用的空间大小，先不算哈希表下面挂的哈希桶的大小，
			//因为哈希表里存放的是指针，每个指针32位下4字节，4294967291=2^32,
			//那么2^32*4=16G，所以只是哈希表占用的空间就是16G的内存，一般的电脑早崩溃了，
			//如果再加上各个哈希桶，也就是各个单链表里的所有节点，那么只能更大！
		};

		//通过当前哈希表有效数据的个数n与数组里的数字比较大小
		for (size_t i = 0; i < __stl_num_primes; ++i)
		{
			if (__stl_prime_list[i] > n)
			{
				//数组里的数据比n大，就返回该数组的数据，
				//作为新表的空间的大小
				return __stl_prime_list[i];
			}
		}

		//如果已经扩到4294967291，那么就不能再扩，返回一个-1
		//转换成无符号整型就是2^32=4294967291
		return -1;
	}




	//该类为哈希表
	//第三个类模板参数hash，就是因为查找、插入成员函数有模，那么就需要将复杂类型的key，
	//转换成可以使用 模% 的整型，这里的第三个类模板参数是接收 仿函数的，
	//第三个类模板参数Hash可以给一个默认的仿函数HashFunc<K>，
	//就可以传自己想用的仿函数
	template<class K, class V, class Hash = HashFunc<K>>
	class HashTable
	{
		//类型名重定义
		typedef HashNode<K, V> Node;

	public:

		//析构函数，为什么我们要自己写一个析构了？？
		//首先，我们知道该类内置类型_size用编译器默认的析构函数即可，
		//但是自定义类型vector会去调用它的析构函数，
		//但是类型vector的析构是可以将vector的空间释放掉，但是vector这个顺序表空间，
		//下面的每个哈希桶，即每个单链表却无法析构，因为每个节点是在堆区开辟的空间，
		//所以这里我们需要手动释放一下每个单链表的空间。
		~HashTable()
		{
			//通过遍历哈希表里每个单链表的头节点
			for (size_t i = 0; i < _tables.size(); ++i)
			{
				Node* cur = _tables[i];
				//将每个单链表里的所有节点的空间释放
				while (cur)
				{
					Node* next = cur->_next;
					free(cur);
					cur = next;
				}
				
				//这里的哈希表里的元素就要置为空指针，因为存放的是 指向每个单链表头节点的地址，
				//所以在每个单链表的头节点的空间释放后，该指针必须置为空指针，不然就是野指针
				_tables[i] = nullptr;
			}
		}


		//插入类类型pair的对象kv
		bool Insert(const pair<K, V>& kv)
		{
			// 去重，如果哈希表已经有键值key的节点，那么就不要插入
			if (Find(kv.first))
			{
				//直接返回false
				return false;
			}


			// 负载因子α=哈希表存放的有效数据/哈希表(顺序表)的空间 到1就扩容
			if (_size == _tables.size())
			{
				//扩容用了该类的成员函数__stl_next_prime()，就不需要用newSize了
				//得到新表的空间的大小newSize
				//size_t newSize = _tables.size() == 0 ? 10 : _tables.size() * 2;
				
				//创建一个新表，即哈希表(顺序表)的空间
				vector<Node*> newTables;
				//用vector的成员函数resize进行开辟空间，每个空间都先初始化为nullptr
				//这里扩容就用到了该类的成员函数__stl_next_prime()，进行扩容
				newTables.resize(__stl_next_prime(_tables.size()), nullptr);
				// 旧表中节点移动映射新表
				for (size_t i = 0; i < _tables.size(); ++i)
				{
					//通过遍历旧表里存放的 指向每个单链表头节点的指针
					Node* cur = _tables[i];
					//将每个哈希桶，即每个单链表的所有节点迁移到新表里
					while (cur)
					{
						//先保存该节点的下一个节点的指针，循环用
						Node* next = cur->_next;

						//第三个类模板参数接收的是仿函数，仿函数也是类，所以要用的话，需要先实例化
						Hash hash;
						//依旧通过线性探测得到新表的存储位置的下标hashi
						size_t hashi = hash(cur->_kv.first) % newTables.size();
						//同样的进行头插，为什么还要进行头插了？？
						//因为扩容后，旧表中某些哈希冲突的节点，到了新表后，
						//就可能不会继续哈希冲突，比如原来旧表10个空间，
						//键值1和11会哈希冲突，放在同一个哈希桶里，即一个单链表里，
						//扩容到新表20个空间后，键值1和键值11就不冲突了，
						//就在新表的有不同位置上了，就会在不同的哈希桶里，即不同的单链表里，
						//所以我们这里要将每个节点进行重新头插到新表了，构造不同的哈希桶。
						//那么插入的cur的指针，链接到上一个头节点，
						cur->_next = newTables[hashi];
						//然后该cur节点，作为头节点存放在哈希表的相应存储位置上
						newTables[hashi] = cur;

						//这一条单链表节点往后走，再次进行头插
						cur = next;
					}

					//while循环后，将已经在旧表中遍历的位置的内容，赋值为空指针,
					//其实这里改不改都无所谓，因为跳出for循环后，会_tables.swap(newTables);
					_tables[i] = nullptr;
				}

				//for循环后，用vector的成员函数swap 进行vector对象的成员变量交换，
				//因为vector的对象newTables是局部变量，出了函数销毁，
				//所以要交换给_tables的成员变量里
				_tables.swap(newTables);
			}

			//第三个类模板参数接收的是仿函数，仿函数也是类，所以要用的话，需要先实例化
			Hash hash;
			//依旧是通过线性探测找到哈希表的储存位置下标hashi
			size_t hashi = hash(kv.first) % _tables.size();
			// 头插或尾插都可以
			//这里用头插，定义一个新节点，通过传入的pair类类型的对象kv
			Node* newnode = new Node(kv);
			//头节点的地址存放在哈希表里的，所以将新节点链接上一次的头节点
			newnode->_next = _tables[hashi];
			//然后这个新节点自己变为头节点，因为是头插，
			//只需要将哈希表里存放的头节点地址改变即可
			_tables[hashi] = newnode;
			//插入后，哈希表的成员变量_size(有效数据)要++一次
			++_size;

			//插入成功后，返回true
			return true;
		}

		//通过键值(关键码)key，即类型K的对象key，来进行查找，返回指向 存放键值key的节点 的指针
		Node* Find(const K& key)
		{
			//如果哈希表(顺序表)的空间为0
			if (_tables.size() == 0)
			{
				//直接返回空指针
				return nullptr;
			}


			//第三个类模板参数接收的是仿函数，仿函数也是类，所以要用的话，需要先实例化
			Hash hash;
			//依旧是通过线性探测找到哈希表的储存位置下标hashi
			size_t hashi = hash(key) % _tables.size();
			//找到该节点所在单链表的 头节点的地址，在对应哈希表储存位置里
			Node* cur = _tables[hashi];
			//通过遍历该单链表，找到指向 存放键值key的节点 的指针
			while (cur)
			{
				if (cur->_kv.first == key)
				{
					//找到就返回
					return cur;
				}

				cur = cur->_next;
			}

			//通过上面循环没有找到，那么就返回空指针
			return nullptr;
		}


		//删除键值key所在的节点
		bool Erase(const K& key)
		{
			//如果哈希表(顺序表)的空间为0，那么就不需要删除的操作
			if (_tables.size() == 0)
			{
				//直接返回false
				return false;
			}

			//第三个类模板参数接收的是仿函数，仿函数也是类，所以要用的话，需要先实例化
			Hash hash;
			//KeyOfT kot;
			//依旧是通过键值key模哈希表(顺序表)的空间大小来 得到哈希表存储位置的下标
			size_t hashi = hash(key) % _tables.size();
			//因为是对单链表的删除，所以我们要有这个前驱指针prev，当删除cur后，
			//可以通过prev来将单链表链接起来。
			Node* prev = nullptr;
			//得到该键值key所在节点 的单链表的头节点
			Node* cur = _tables[hashi];
			//遍历该单链表里的所有节点，找到键值是key的节点
			while (cur)
			{
				
				if (cur->_kv.first == key)
				{
					// 特殊情况：删除的节点是该单链表的头节点
					//即前驱指针就是一开始我们定义的nullptr
					if (prev == nullptr)
					{
						//直接将第二节点的地址放入 对应哈希表的存储位置里
						_tables[hashi] = cur->_next;
					}
					//不是上面的特殊情况
					else
					{
						//先将删除的cur的前驱指针prev链接 cur的下一个节点
						prev->_next = cur->_next;
					}

					//通过上面的链接后，删除该节点cur
					delete cur;
					//成员变量_size(记录有效数据的)需要--一下
					--_size;

					//删除成功后，返回true
					return true;
				}

				//没找到继续遍历该单链表
				prev = cur;
				cur = cur->_next;
			}

			//跳出循环后，没有删除成功，那么就返回false
			return false;
		}


		//哈希表有效数据的个数
		size_t Size()
		{
			return _size;
		}


		// 哈希表的长度，即哈希表(顺序表)的空间大小
		size_t TablesSize()
		{
			return _tables.size();
		}


		// 哈希桶的个数
		size_t BucketNum()
		{
			size_t num = 0;
			for (size_t i = 0; i < _tables.size(); ++i)
			{
				if (_tables[i])
				{
					++num;
				}
			}

			return num;
		}


		//最长的哈希桶的长度
		size_t MaxBucketLenth()
		{
			size_t maxLen = 0;
			for (size_t i = 0; i < _tables.size(); ++i)
			{
				size_t len = 0;
				Node* cur = _tables[i];
				while (cur)
				{
					++len;
					cur = cur->_next;
				}

				//if (len > 0)
					//printf("[%d]号桶长度:%d\n", i, len);

				if (len > maxLen)
				{
					maxLen = len;
				}
			}

			return maxLen;
		}



	private:
		//也是用的顺序表的空间，作为哈希表的空间，
		//只不过哈希表里存放的元素是每个单链表头节点的指针 ，
		//所以哈希表里的空间(即顺序表里的空间)的元素类型为Node*
		vector<Node*> _tables;
		// 存储有效数据个数
		size_t _size = 0;
	};


	//下面是类外，命名空间里


	void TestHT1()
	{
		int a[] = { 1, 11, 4, 15, 26, 7, 44,55,99,78 };
		HashTable<int, int> ht;
		for (auto e : a)
		{
			//验证一下插入，这里直接用类类型make_pair就可以不用实例化对象，直接是匿名对象
			ht.Insert(make_pair(e, e));
		}

		ht.Insert(make_pair(22, 22));
	}


	void TestHT2()
	{
		string arr[] = { "苹果", "西瓜", "苹果", "西瓜", "苹果", "苹果", "西瓜", "苹果", "香蕉", "苹果", "香蕉" };

		//HashTable<string, int, HashFunc<string>> countHT;
		HashTable<string, int> countHT;
		for (auto& str : arr)
		{
			auto ptr = countHT.Find(str);
			if (ptr)
			{
				ptr->_kv.second++;
			}
			else
			{
				countHT.Insert(make_pair(str, 1));
			}
		}
	}


	//通过产生随机数来进行测试，
	//我们通过随机数可以得出一个结论，就是一般来说，每个哈希桶挂的数据的个数
	//都是相差不多的，一般相差的不大
	void TestHT3()
	{

		int n = 19000000;
		vector<int> v;
		v.reserve(n);
		srand(time(0));
		for (int i = 0; i < n; ++i)
		{
			//这个重复就是随机数重复的意思，这样是一个小技巧：rand() + i，
			//这样保证产生的随机数相同的少
			v.push_back(rand() + i);  // 重复少
			//v.push_back(rand());  // 重复多
		}

		size_t begin1 = clock();
		HashTable<int, int> ht;
		for (auto e : v)
		{
			ht.Insert(make_pair(e, e));
		}
		size_t end1 = clock();

		cout << "数据个数:" << ht.Size() << endl;
		cout << "表的长度:" << ht.TablesSize() << endl;
		cout << "桶的个数:" << ht.BucketNum() << endl;
		cout << "平均每个桶的长度:" << (double)ht.Size() / (double)ht.BucketNum() << endl;
		cout << "最长的桶的长度:" << ht.MaxBucketLenth() << endl;
		cout << "负载因子:" << (double)ht.Size() / (double)ht.TablesSize() << endl;
	}


}